{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_segments=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/miniconda3/envs/mmxai/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading CPU energy: 'int' object has no attribute 'power'\n",
      "Error reading GPU energy: Command '['nvidia-smi', '--query-gpu=energy.draw', '--format=csv,noheader,nounits']' returned non-zero exit status 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c88763cf70d49c5a79ce9a8abb1b249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing videos:   7%|6         | 50/748 [00:00<?, ?video/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/miniconda3/envs/mmxai/lib/python3.12/site-packages/transformers/feature_extraction_utils.py:141: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  return torch.tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing segment: shape '[1, 10, 14, 8, 768]' is invalid for input of size 903168\n",
      "Error processing segment: shape '[1, 10, 14, 8, 768]' is invalid for input of size 903168\n",
      "Error processing segment: shape '[1, 10, 14, 8, 768]' is invalid for input of size 903168\n",
      "Error processing segment: shape '[1, 10, 14, 8, 768]' is invalid for input of size 903168\n",
      "Error processing segment: shape '[1, 10, 14, 8, 768]' is invalid for input of size 903168\n",
      "Error processing segment: shape '[1, 10, 14, 8, 768]' is invalid for input of size 903168\n",
      "Error processing segment: shape '[1, 10, 14, 8, 768]' is invalid for input of size 903168\n",
      "Error processing segment: shape '[1, 10, 14, 8, 768]' is invalid for input of size 903168\n",
      "Skipping video wL4EN5CBU9Q.mp4 due to empty segment outputs.\n",
      "Error processing segment: shape '[1, 17, 14, 8, 768]' is invalid for input of size 1505280\n",
      "Error processing segment: shape '[1, 17, 14, 8, 768]' is invalid for input of size 1505280\n",
      "Error processing segment: shape '[1, 17, 14, 8, 768]' is invalid for input of size 1505280\n",
      "Error processing segment: shape '[1, 17, 14, 8, 768]' is invalid for input of size 1505280\n",
      "Error processing segment: shape '[1, 17, 14, 8, 768]' is invalid for input of size 1505280\n",
      "Error processing segment: shape '[1, 17, 14, 8, 768]' is invalid for input of size 1505280\n",
      "Error processing segment: shape '[1, 17, 14, 8, 768]' is invalid for input of size 1505280\n",
      "Error processing segment: shape '[1, 17, 14, 8, 768]' is invalid for input of size 1505280\n",
      "Skipping video 94uIR7fT_KM.mp4 due to empty segment outputs.\n",
      "Error processing video y0f7calGty4.mp4: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import av\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "import psutil\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AutoImageProcessor, TimesformerForVideoClassification\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, model_name, image_processor_name, device='cuda'):\n",
    "        self.model = self.load_model(model_name)\n",
    "        self.image_processor = AutoImageProcessor.from_pretrained(image_processor_name)\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        if \"timesformer\" in model_name.lower():\n",
    "            return TimesformerForVideoClassification.from_pretrained(model_name)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    def split_video_into_segments(self, container, n_segments=8, frames_per_segment=16):\n",
    "        frame_list = [frame.to_image() for frame in container.decode(video=0)]\n",
    "        total_frames = len(frame_list)\n",
    "        segment_length = total_frames // n_segments\n",
    "        segments = []\n",
    "        for i in range(n_segments):\n",
    "            start = i * segment_length\n",
    "            end = min(start + segment_length, total_frames)\n",
    "            segment_frames = frame_list[start:end] if end - start == segment_length else frame_list[start:] + [frame_list[-1]] * (segment_length - (end - start))\n",
    "            segments.append(segment_frames[:frames_per_segment])\n",
    "        return segments\n",
    "\n",
    "    def predict_video_and_segments(self, container, true_label):\n",
    "        video_segments = self.split_video_into_segments(container)\n",
    "        segment_outputs = []\n",
    "        with torch.no_grad():\n",
    "            for segment in video_segments:\n",
    "                inputs = self.image_processor(list(segment), return_tensors=\"pt\")\n",
    "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "                try:\n",
    "                    outputs = self.model(**inputs)\n",
    "                    logits = outputs.logits\n",
    "                    probabilities = F.softmax(logits, dim=-1)\n",
    "                    pred_label = logits.argmax(-1).item()\n",
    "                    pred_score = probabilities[0, pred_label].item()\n",
    "                    segment_outputs.append((pred_label, pred_score, probabilities))  # Ensure this returns a tuple\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"Error processing segment: {e}\")\n",
    "                    continue\n",
    "        return segment_outputs\n",
    "\n",
    "\n",
    "class TemporalShap:\n",
    "    def __init__(self, num_samples=100):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def approximate_shapley_values(self, segment_outputs, label_index):\n",
    "        n = len(segment_outputs)\n",
    "        shapley_values = [0] * n\n",
    "        for _ in range(self.num_samples):\n",
    "            random_subset = sorted(range(n), key=lambda _: random.random())\n",
    "            subset_prob = torch.zeros_like(segment_outputs[0][2])\n",
    "            for i, index in enumerate(random_subset):\n",
    "                old_contribution = subset_prob[0, label_index].item()\n",
    "                subset_prob += segment_outputs[index][2]\n",
    "                subset_prob /= (i + 1)\n",
    "                new_contribution = subset_prob[0, label_index].item()\n",
    "                shapley_values[index] += new_contribution - old_contribution\n",
    "        return [val / self.num_samples for val in shapley_values]\n",
    "\n",
    "    def exact_shapley_values(self, segment_outputs, label_index):\n",
    "        n = len(segment_outputs)\n",
    "        shapley_values = [0] * n\n",
    "        all_indices = list(range(n))\n",
    "        for i in all_indices:\n",
    "            marginal_contributions = []\n",
    "            for subset_size in range(n):\n",
    "                subsets = list(combinations([x for x in all_indices if x != i], subset_size))\n",
    "                for subset in subsets:\n",
    "                    subset_prob = torch.zeros_like(segment_outputs[0][2])\n",
    "                    if subset:\n",
    "                        subset_prob = torch.mean(torch.stack([segment_outputs[j][2] for j in subset]), dim=0)\n",
    "                    with_i_prob = (subset_prob * len(subset) + segment_outputs[i][2]) / (len(subset) + 1)\n",
    "                    marginal_contributions.append(with_i_prob[0, label_index].item() - subset_prob[0, label_index].item())\n",
    "            shapley_values[i] = np.mean(marginal_contributions)\n",
    "        return shapley_values\n",
    "\n",
    "def get_gpu_energy():\n",
    "    try:\n",
    "        result = subprocess.check_output(['nvidia-smi', '--query-gpu=energy.draw', '--format=csv,noheader,nounits'])\n",
    "        return float(result.strip().split()[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading GPU energy: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def get_cpu_energy():\n",
    "    try:\n",
    "        energy = 0.0\n",
    "        for domain in psutil.sensors_battery():\n",
    "            energy += domain.power * domain.energy\n",
    "        return energy\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CPU energy: {e}\")\n",
    "        return 0.0\n",
    "    \n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "def get_gpu_power_draw():\n",
    "    try:\n",
    "        # This command retrieves the current power usage in watts.\n",
    "        result = subprocess.check_output(['nvidia-smi', '--query-gpu=power.draw', '--format=csv,noheader,nounits'], text=True)\n",
    "        return float(result.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading GPU power: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def get_system_time():\n",
    "    return time.time()  # Return the current system time in seconds\n",
    "\n",
    "# Example usage in your processing function\n",
    "start_time = get_system_time()\n",
    "initial_gpu_power = get_gpu_power_draw()\n",
    "\n",
    "# Execute your long-running process here\n",
    "time.sleep(10)  # Simulating a delay\n",
    "\n",
    "end_time = get_system_time()\n",
    "final_gpu_power = get_gpu_power_draw()\n",
    "\n",
    "time_consumed = end_time - start_time\n",
    "average_gpu_power = (initial_gpu_power + final_gpu_power) / 2\n",
    "energy_consumed = average_gpu_power * (time_consumed / 3600)  # Convert power usage in watts to kilowatt-hours if needed\n",
    "\n",
    "def process_videos(video_processor, shap_calculator, sampled_files, true_labels, use_exact=False, start_index=0):\n",
    "    predictions = []\n",
    "    for idx, (video_file, true_label) in tqdm(enumerate(zip(sampled_files, true_labels)), desc=\"Processing videos\", total=len(sampled_files), initial=start_index, unit=\"video\"):\n",
    "        if idx < start_index:\n",
    "            continue\n",
    "        file_path = os.path.join(config[\"video_directory\"], video_file)\n",
    "        container = av.open(file_path)\n",
    "        try:\n",
    "            segment_outputs = video_processor.predict_video_and_segments(container, true_label)\n",
    "            if not segment_outputs:\n",
    "                print(f\"Skipping video {video_file} due to empty segment outputs.\")\n",
    "                continue\n",
    "            video_probs = torch.mean(torch.stack([output[2] for output in segment_outputs]), dim=0)\n",
    "            video_pred_label = video_probs.argmax().item()\n",
    "            video_pred_score = video_probs[0, video_pred_label].item()\n",
    "            video_true_score = video_probs[0, true_label].item()\n",
    "            \n",
    "            if use_exact:\n",
    "                sv_true_label = shap_calculator.exact_shapley_values(segment_outputs, true_label)\n",
    "                sv_video_pred = shap_calculator.exact_shapley_values(segment_outputs, video_pred_label)\n",
    "            else:\n",
    "                sv_true_label = shap_calculator.approximate_shapley_values(segment_outputs, true_label)\n",
    "                sv_video_pred = shap_calculator.approximate_shapley_values(segment_outputs, video_pred_label)\n",
    "            \n",
    "            prediction = (video_file, video_pred_label, video_pred_score, video_true_score, true_label, segment_outputs)  # Ensure tuple has 6 elements\n",
    "            predictions.append(prediction)\n",
    "            save_partial_results(prediction, \"results.json\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video {video_file}: {e}\")\n",
    "            continue\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "def save_partial_results(prediction, filename):\n",
    "    video_file, video_pred_label, video_pred_score, video_true_score, video_true_label, segment_outputs = prediction\n",
    "    video_result = {\n",
    "        \"video_file\": video_file,\n",
    "        \"video_pred_label\": video_pred_label,\n",
    "        \"video_pred_score\": video_pred_score,\n",
    "        \"video_true_score\": video_true_score,\n",
    "        \"video_true_label\": video_true_label,\n",
    "        \"segments\": []\n",
    "    }\n",
    "    for i, (segment_label, segment_score, probabilities) in enumerate(segment_outputs):\n",
    "        segment_video_label_score = probabilities[0, video_pred_label].item()\n",
    "        segment_true_label_score = probabilities[0, video_true_label].item()\n",
    "        video_result[\"segments\"].append({\n",
    "            \"segment_index\": i + 1,\n",
    "            \"segment_label\": segment_label,\n",
    "            \"segment_score\": segment_score,\n",
    "            \"segment_video_label_score\": segment_video_label_score,\n",
    "            \"segment_true_label_score\": segment_true_label_score,\n",
    "            # Assuming sv_true_label and sv_video_pred are not needed here or add them back if available in predictions\n",
    "        })\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r+\") as f:\n",
    "            results = json.load(f)\n",
    "            results.append(video_result)\n",
    "            f.seek(0)\n",
    "            json.dump(results, f, indent=4)\n",
    "    else:\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump([video_result], f, indent=4)\n",
    "\n",
    "\n",
    "def load_existing_results(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "            processed_files = {result[\"video_file\"] for result in results}\n",
    "            return results, processed_files\n",
    "    return [], set()\n",
    "\n",
    "def save_results(predictions, filename=\"results.json\"):\n",
    "    results = []\n",
    "    for video_file, video_pred_label, video_pred_score, video_true_score, true_label, segment_outputs in predictions:\n",
    "        video_result = {\n",
    "            \"video_file\": video_file,\n",
    "            \"video_pred_label\": video_pred_label,\n",
    "            \"video_pred_score\": video_pred_score,\n",
    "            \"video_true_score\": video_true_score,\n",
    "            \"video_true_label\": true_label,\n",
    "            \"segments\": []\n",
    "        }\n",
    "        for i, (segment_label, segment_score, probabilities) in enumerate(segment_outputs):\n",
    "            segment_video_label_score = probabilities[0, video_pred_label].item()\n",
    "            segment_true_label_score = probabilities[0, true_label].item()\n",
    "            video_result[\"segments\"].append({\n",
    "                \"segment_index\": i + 1,\n",
    "                \"segment_label\": segment_label,\n",
    "                \"segment_score\": segment_score,\n",
    "                \"segment_video_label_score\": segment_video_label_score,\n",
    "                \"segment_true_label_score\": segment_true_label_score,\n",
    "                # Assuming sv_true_label and sv_video_pred are not needed here or add them back if available in predictions\n",
    "            })\n",
    "        results.append(video_result)\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    true_labels = [pred[4] for pred in predictions]\n",
    "    pred_labels = [pred[1] for pred in predictions]\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, pred_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def save_performance_metrics(accuracy, precision, recall, f1, time_consumed, cpu_energy, gpu_energy, filename=\"performance.json\"):\n",
    "    performance = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"time_consumed\": time_consumed,\n",
    "        \"cpu_energy\": cpu_energy,\n",
    "        \"gpu_energy\": gpu_energy\n",
    "    }\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(performance, f, indent=4)\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    \"model_name\": \"facebook/timesformer-base-finetuned-k400\",\n",
    "    \"image_processor_name\": \"MCG-NJU/videomae-base-finetuned-kinetics\",\n",
    "    \"num_samples\": 100,\n",
    "    \"num_classes\": 30,  # For flexible dataset input\n",
    "    \"num_samples_per_class\": 25,  # For flexible dataset input\n",
    "    \"video_list_path\": \"archive/kinetics400_val_list_videos.txt\",\n",
    "    \"video_directory\": \"archive/videos_val\",\n",
    "    \"use_exact\": True\n",
    "}\n",
    "\n",
    "# Initialize processors\n",
    "video_processor = VideoProcessor(config[\"model_name\"], config[\"image_processor_name\"])\n",
    "shap_calculator = TemporalShap(num_samples=config[\"num_samples\"])\n",
    "\n",
    "# Load existing results\n",
    "existing_results, processed_files = load_existing_results(\"results.json\")\n",
    "\n",
    "# Read video list and organize by categories if necessary\n",
    "video_labels = defaultdict(list)\n",
    "with open(config[\"video_list_path\"], \"r\") as f:\n",
    "    for line in f:\n",
    "        name, label = line.strip().split()\n",
    "        video_labels[int(label)].append(name)\n",
    "\n",
    "# Prepare video samples for the configured number of classes and samples\n",
    "sampled_files = []\n",
    "true_labels = []\n",
    "selected_classes = random.sample(list(video_labels.keys()), config[\"num_classes\"])\n",
    "for cls in selected_classes:\n",
    "    sampled_files.extend(random.sample(video_labels[cls], config[\"num_samples_per_class\"]))\n",
    "    true_labels.extend([cls] * config[\"num_samples_per_class\"])\n",
    "\n",
    "# Filter unprocessed files\n",
    "unprocessed_files = [f for f in sampled_files if f not in processed_files]\n",
    "unprocessed_labels = [true_labels[sampled_files.index(f)] for f in unprocessed_files]\n",
    "\n",
    "# Record start time and energy consumption\n",
    "start_time = time.time()\n",
    "initial_cpu_energy = get_cpu_energy()\n",
    "initial_gpu_energy = get_gpu_energy()\n",
    "\n",
    "# Process videos\n",
    "video_data = process_videos(video_processor, shap_calculator, unprocessed_files, unprocessed_labels, use_exact=config[\"use_exact\"], start_index=len(existing_results))\n",
    "\n",
    "# Record end time and energy consumption\n",
    "end_time = time.time()\n",
    "final_cpu_energy = get_cpu_energy()\n",
    "final_gpu_energy = get_gpu_energy()\n",
    "time_consumed = end_time - start_time\n",
    "cpu_energy_consumed = final_cpu_energy - initial_cpu_energy\n",
    "gpu_energy_consumed = final_gpu_energy - initial_gpu_energy\n",
    "\n",
    "# Combine existing results with new data\n",
    "all_results = existing_results + video_data\n",
    "\n",
    "# Save results\n",
    "save_results(all_results)\n",
    "\n",
    "# Compute and output metrics\n",
    "accuracy, precision, recall, f1 = compute_metrics(all_results)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Save performance metrics\n",
    "save_performance_metrics(accuracy, precision, recall, f1, time_consumed, cpu_energy_consumed, gpu_energy_consumed, filename=\"performance.json\")\n",
    "\n",
    "\n",
    "# Print detailed results\n",
    "for video_file, video_pred_label, video_pred_score, video_true_score, true_label, segment_outputs, sv_true_label, sv_video_pred in all_results:\n",
    "    print(f\"Video: {video_file}, Overall Predicted Label = {video_pred_label}, Overall Prediction Score = {video_pred_score:.4f}, True Label = {true_label}, True Label Score = {video_true_score:.4f}\")\n",
    "    for i, (segment_label, segment_score, probabilities) in enumerate(segment_outputs):\n",
    "        segment_video_label_score = probabilities[0, video_pred_label].item()\n",
    "        segment_true_label_score = probabilities[0, true_label].item()\n",
    "        print(f\"  Segment {i+1}: Predicted Label = {segment_label}, Prediction Score = {segment_score:.4f}, Segment Video Label Score = {segment_video_label_score:.4f}, Segment True Label Score = {segment_true_label_score:.4f}, SV True Label = {sv_true_label[i]:.4f}, SV Predicted Label = {sv_video_pred[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmxai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
