{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segment_duration=1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/miniconda3/envs/mmxai/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading CPU energy: 'int' object has no attribute 'power'\n",
      "Error reading GPU energy: Command '['nvidia-smi', '--query-gpu=energy.draw', '--format=csv,noheader,nounits']' returned non-zero exit status 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3a2ec5f76540d5851059bd04acb25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing videos: 142video [00:00, ?video/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading CPU energy: 'int' object has no attribute 'power'\n",
      "Error reading GPU energy: Command '['nvidia-smi', '--query-gpu=energy.draw', '--format=csv,noheader,nounits']' returned non-zero exit status 2.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 8, got 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 330\u001b[0m\n\u001b[1;32m    327\u001b[0m all_results \u001b[38;5;241m=\u001b[39m existing_results \u001b[38;5;241m+\u001b[39m video_data\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m \u001b[43msave_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# Compute and output metrics\u001b[39;00m\n\u001b[1;32m    333\u001b[0m accuracy, precision, recall, f1 \u001b[38;5;241m=\u001b[39m compute_metrics(all_results)\n",
      "Cell \u001b[0;32mIn[7], line 221\u001b[0m, in \u001b[0;36msave_results\u001b[0;34m(predictions, filename)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_results\u001b[39m(predictions, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults.json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    220\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m video_file, video_pred_label, video_pred_score, video_true_score, video_true_label, segment_outputs, sv_true_label, sv_video_pred \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[1;32m    222\u001b[0m         video_result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_file\u001b[39m\u001b[38;5;124m\"\u001b[39m: video_file,\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_pred_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: video_pred_label,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[1;32m    229\u001b[0m         }\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, (segment_label, segment_score, probabilities) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(segment_outputs):\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 8, got 6)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import av\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "import psutil\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AutoImageProcessor, TimesformerForVideoClassification\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, model_name, image_processor_name, device='cuda'):\n",
    "        self.model = self.load_model(model_name)\n",
    "        self.image_processor = AutoImageProcessor.from_pretrained(image_processor_name)\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        if \"timesformer\" in model_name.lower():\n",
    "            return TimesformerForVideoClassification.from_pretrained(model_name)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    def split_video_into_segments(self, container, segment_duration=1, frames_per_segment=16):\n",
    "        frame_list = [frame.to_image() for frame in container.decode(video=0)]\n",
    "        total_frames = len(frame_list)\n",
    "        fps = container.streams.video[0].average_rate\n",
    "        segment_length = int(fps * segment_duration)\n",
    "        \n",
    "        segments = []\n",
    "        for start in range(0, total_frames, segment_length):\n",
    "            end = min(start + segment_length, total_frames)\n",
    "            segment_frames = frame_list[start:end]\n",
    "            if len(segment_frames) < frames_per_segment:\n",
    "                segment_frames.extend([frame_list[-1]] * (frames_per_segment - len(segment_frames)))\n",
    "            segments.append(segment_frames[:frames_per_segment])\n",
    "        return segments\n",
    "\n",
    "    def predict_video_and_segments(self, container, true_label):\n",
    "        video_segments = self.split_video_into_segments(container)\n",
    "        segment_outputs = []\n",
    "        with torch.no_grad():\n",
    "            for segment in video_segments:\n",
    "                inputs = self.image_processor(list(segment), return_tensors=\"pt\")\n",
    "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "                try:\n",
    "                    outputs = self.model(**inputs)\n",
    "                    logits = outputs.logits\n",
    "                    probabilities = F.softmax(logits, dim=-1)\n",
    "                    pred_label = logits.argmax(-1).item()\n",
    "                    pred_score = probabilities[0, pred_label].item()\n",
    "                    segment_outputs.append((pred_label, pred_score, probabilities))\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"Error processing segment: {e}\")\n",
    "                    continue\n",
    "        return segment_outputs\n",
    "\n",
    "class TemporalShap:\n",
    "    def __init__(self, num_samples=100):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def approximate_shapley_values(self, segment_outputs, label_index):\n",
    "        n = len(segment_outputs)\n",
    "        shapley_values = [0] * n\n",
    "        for _ in range(self.num_samples):\n",
    "            random_subset = sorted(range(n), key=lambda _: random.random())\n",
    "            subset_prob = torch.zeros_like(segment_outputs[0][2])\n",
    "            for i, index in enumerate(random_subset):\n",
    "                old_contribution = subset_prob[0, label_index].item()\n",
    "                subset_prob += segment_outputs[index][2]\n",
    "                subset_prob /= (i + 1)\n",
    "                new_contribution = subset_prob[0, label_index].item()\n",
    "                shapley_values[index] += new_contribution - old_contribution\n",
    "        return [val / self.num_samples for val in shapley_values]\n",
    "\n",
    "    def exact_shapley_values(self, segment_outputs, label_index):\n",
    "        n = len(segment_outputs)\n",
    "        shapley_values = [0] * n\n",
    "        all_indices = list(range(n))\n",
    "        for i in all_indices:\n",
    "            marginal_contributions = []\n",
    "            for subset_size in range(n):\n",
    "                subsets = list(combinations([x for x in all_indices if x != i], subset_size))\n",
    "                for subset in subsets:\n",
    "                    subset_prob = torch.zeros_like(segment_outputs[0][2])\n",
    "                    if subset:\n",
    "                        subset_prob = torch.mean(torch.stack([segment_outputs[j][2] for j in subset]), dim=0)\n",
    "                    with_i_prob = (subset_prob * len(subset) + segment_outputs[i][2]) / (len(subset) + 1)\n",
    "                    marginal_contributions.append(with_i_prob[0, label_index].item() - subset_prob[0, label_index].item())\n",
    "            shapley_values[i] = np.mean(marginal_contributions)\n",
    "        return shapley_values\n",
    "\n",
    "def get_gpu_energy():\n",
    "    try:\n",
    "        result = subprocess.check_output(['nvidia-smi', '--query-gpu=energy.draw', '--format=csv,noheader,nounits'])\n",
    "        return float(result.strip().split()[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading GPU energy: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def get_cpu_energy():\n",
    "    try:\n",
    "        energy = 0.0\n",
    "        for domain in psutil.sensors_battery():\n",
    "            energy += domain.power * domain.energy\n",
    "        return energy\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CPU energy: {e}\")\n",
    "        return 0.0\n",
    "    \n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "def get_gpu_power_draw():\n",
    "    try:\n",
    "        # This command retrieves the current power usage in watts.\n",
    "        result = subprocess.check_output(['nvidia-smi', '--query-gpu=power.draw', '--format=csv,noheader,nounits'], text=True)\n",
    "        return float(result.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading GPU power: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def get_system_time():\n",
    "    return time.time()  # Return the current system time in seconds\n",
    "\n",
    "# Example usage in your processing function\n",
    "start_time = get_system_time()\n",
    "initial_gpu_power = get_gpu_power_draw()\n",
    "\n",
    "# Execute your long-running process here\n",
    "time.sleep(10)  # Simulating a delay\n",
    "\n",
    "end_time = get_system_time()\n",
    "final_gpu_power = get_gpu_power_draw()\n",
    "\n",
    "time_consumed = end_time - start_time\n",
    "average_gpu_power = (initial_gpu_power + final_gpu_power) / 2\n",
    "energy_consumed = average_gpu_power * (time_consumed / 3600)  # Convert power usage in watts to kilowatt-hours if needed\n",
    "\n",
    "def process_videos(video_processor, shap_calculator, sampled_files, true_labels, use_exact=False, start_index=0):\n",
    "    predictions = []\n",
    "    for idx, (video_file, true_label) in tqdm(enumerate(zip(sampled_files, true_labels)), desc=\"Processing videos\", total=len(sampled_files), initial=start_index, unit=\"video\"):\n",
    "        if idx < start_index:\n",
    "            continue\n",
    "        file_path = os.path.join(config[\"video_directory\"], video_file)\n",
    "        container = av.open(file_path)\n",
    "        try:\n",
    "            segment_outputs = video_processor.predict_video_and_segments(container, true_label)\n",
    "            if not segment_outputs:\n",
    "                print(f\"Skipping video {video_file} due to empty segment outputs.\")\n",
    "                continue\n",
    "            video_probs = torch.mean(torch.stack([output[2] for output in segment_outputs]), dim=0)\n",
    "            video_pred_label = video_probs.argmax().item()\n",
    "            video_pred_score = video_probs[0, video_pred_label].item()\n",
    "            video_true_score = video_probs[0, true_label].item()\n",
    "            \n",
    "            if use_exact:\n",
    "                sv_true_label = shap_calculator.exact_shapley_values(segment_outputs, true_label)\n",
    "                sv_video_pred = shap_calculator.exact_shapley_values(segment_outputs, video_pred_label)\n",
    "            else:\n",
    "                sv_true_label = shap_calculator.approximate_shapley_values(segment_outputs, true_label)\n",
    "                sv_video_pred = shap_calculator.approximate_shapley_values(segment_outputs, video_pred_label)\n",
    "            \n",
    "            prediction = (video_file, video_pred_label, video_pred_score, video_true_score, true_label, sv_true_label, sv_video_pred, segment_outputs)\n",
    "            predictions.append(prediction)\n",
    "            save_partial_results(prediction, \"results.json\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video {video_file}: {e}\")\n",
    "            continue\n",
    "    return predictions\n",
    "\n",
    "def save_partial_results(prediction, filename):\n",
    "    video_file, video_pred_label, video_pred_score, video_true_score, video_true_label, sv_true_label, sv_video_pred, segment_outputs = prediction\n",
    "    video_result = {\n",
    "        \"video_file\": video_file,\n",
    "        \"video_pred_label\": video_pred_label,\n",
    "        \"video_pred_score\": video_pred_score,\n",
    "        \"video_true_score\": video_true_score,\n",
    "        \"video_true_label\": video_true_label,\n",
    "        \"segments\": []\n",
    "    }\n",
    "    for i, (segment_label, segment_score, probabilities) in enumerate(segment_outputs):\n",
    "        segment_video_label_score = probabilities[0, video_pred_label].item()\n",
    "        segment_true_label_score = probabilities[0, video_true_label].item()\n",
    "        video_result[\"segments\"].append({\n",
    "            \"segment_index\": i + 1,\n",
    "            \"segment_label\": segment_label,\n",
    "            \"segment_score\": segment_score,\n",
    "            \"segment_video_label_score\": segment_video_label_score,\n",
    "            \"segment_true_label_score\": segment_true_label_score,\n",
    "            \"sv_true_label\": sv_true_label[i],\n",
    "            \"sv_video_pred\": sv_video_pred[i]\n",
    "        })\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r+\") as f:\n",
    "            results = json.load(f)\n",
    "            results.append(video_result)\n",
    "            f.seek(0)\n",
    "            json.dump(results, f, indent=4)\n",
    "    else:\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump([video_result], f, indent=4)\n",
    "\n",
    "def load_existing_results(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "            processed_files = {result[\"video_file\"] for result in results}\n",
    "            return results, processed_files\n",
    "    return [], set()\n",
    "\n",
    "def save_results(predictions, filename=\"results.json\"):\n",
    "    results = []\n",
    "    for video_file, video_pred_label, video_pred_score, video_true_score, video_true_label, segment_outputs, sv_true_label, sv_video_pred in predictions:\n",
    "        video_result = {\n",
    "            \"video_file\": video_file,\n",
    "            \"video_pred_label\": video_pred_label,\n",
    "            \"video_pred_score\": video_pred_score,\n",
    "            \"video_true_score\": video_true_score,\n",
    "            \"video_true_label\": video_true_label,\n",
    "            \"segments\": []\n",
    "        }\n",
    "        for i, (segment_label, segment_score, probabilities) in enumerate(segment_outputs):\n",
    "            segment_video_label_score = probabilities[0, video_pred_label].item()\n",
    "            segment_true_label_score = probabilities[0, video_true_label].item()\n",
    "            video_result[\"segments\"].append({\n",
    "                \"segment_index\": i + 1,\n",
    "                \"segment_label\": segment_label,\n",
    "                \"segment_score\": segment_score,\n",
    "                \"segment_video_label_score\": segment_video_label_score,\n",
    "                \"segment_true_label_score\": segment_true_label_score,\n",
    "                \"sv_true_label\": sv_true_label[i],\n",
    "                \"sv_video_pred\": sv_video_pred[i]\n",
    "            })\n",
    "        results.append(video_result)\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    true_labels = [pred[4] for pred in predictions]\n",
    "    pred_labels = [pred[1] for pred in predictions]\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, pred_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def save_performance_metrics(accuracy, precision, recall, f1, time_consumed, cpu_energy, gpu_energy, filename=\"performance.json\"):\n",
    "    performance = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"time_consumed\": time_consumed,\n",
    "        \"cpu_energy\": cpu_energy,\n",
    "        \"gpu_energy\": gpu_energy\n",
    "    }\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(performance, f, indent=4)\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    \"model_name\": \"facebook/timesformer-base-finetuned-k400\",\n",
    "    \"image_processor_name\": \"MCG-NJU/videomae-base-finetuned-kinetics\",\n",
    "    \"num_samples\": 10,\n",
    "    \"num_classes\": 3,  # For flexible dataset input\n",
    "    \"num_samples_per_class\": 10,  # For flexible dataset input\n",
    "    \"video_list_path\": \"archive/kinetics400_val_list_videos.txt\",\n",
    "    \"video_directory\": \"archive/videos_val\",\n",
    "    \"use_exact\": True\n",
    "}\n",
    "\n",
    "# Initialize processors\n",
    "video_processor = VideoProcessor(config[\"model_name\"], config[\"image_processor_name\"])\n",
    "shap_calculator = TemporalShap(num_samples=config[\"num_samples\"])\n",
    "\n",
    "# Load existing results\n",
    "existing_results, processed_files = load_existing_results(\"results.json\")\n",
    "\n",
    "# Read video list and organize by categories if necessary\n",
    "video_labels = defaultdict(list)\n",
    "with open(config[\"video_list_path\"], \"r\") as f:\n",
    "    for line in f:\n",
    "        name, label = line.strip().split()\n",
    "        video_labels[int(label)].append(name)\n",
    "\n",
    "# Prepare video samples for the configured number of classes and samples\n",
    "sampled_files = []\n",
    "true_labels = []\n",
    "selected_classes = random.sample(list(video_labels.keys()), config[\"num_classes\"])\n",
    "for cls in selected_classes:\n",
    "    sampled_files.extend(random.sample(video_labels[cls], config[\"num_samples_per_class\"]))\n",
    "    true_labels.extend([cls] * config[\"num_samples_per_class\"])\n",
    "\n",
    "# Filter unprocessed files\n",
    "unprocessed_files = [f for f in sampled_files if f not in processed_files]\n",
    "unprocessed_labels = [true_labels[sampled_files.index(f)] for f in unprocessed_files]\n",
    "\n",
    "# Record start time and energy consumption\n",
    "start_time = time.time()\n",
    "initial_cpu_energy = get_cpu_energy()\n",
    "initial_gpu_energy = get_gpu_energy()\n",
    "\n",
    "# Process videos\n",
    "video_data = process_videos(video_processor, shap_calculator, unprocessed_files, unprocessed_labels, use_exact=config[\"use_exact\"], start_index=len(existing_results))\n",
    "\n",
    "# Record end time and energy consumption\n",
    "end_time = time.time()\n",
    "final_cpu_energy = get_cpu_energy()\n",
    "final_gpu_energy = get_gpu_energy()\n",
    "time_consumed = end_time - start_time\n",
    "cpu_energy_consumed = final_cpu_energy - initial_cpu_energy\n",
    "gpu_energy_consumed = final_gpu_energy - initial_gpu_energy\n",
    "\n",
    "# Combine existing results with new data\n",
    "all_results = existing_results + video_data\n",
    "\n",
    "# Save results\n",
    "save_results(all_results)\n",
    "\n",
    "# Compute and output metrics\n",
    "accuracy, precision, recall, f1 = compute_metrics(all_results)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Save performance metrics\n",
    "save_performance_metrics(accuracy, precision, recall, f1, time_consumed, cpu_energy_consumed, gpu_energy_consumed, filename=\"performance.json\")\n",
    "\n",
    "# Print detailed results\n",
    "for video_file, video_pred_label, video_pred_score, video_true_score, true_label, segment_outputs, sv_true_label, sv_video_pred in all_results:\n",
    "    print(f\"Video: {video_file}, Overall Predicted Label = {video_pred_label}, Overall Prediction Score = {video_pred_score:.4f}, True Label = {true_label}, True Label Score = {video_true_score:.4f}\")\n",
    "    for i, (segment_label, segment_score, probabilities) in enumerate(segment_outputs):\n",
    "        segment_video_label_score = probabilities[0, video_pred_label].item()\n",
    "        segment_true_label_score = probabilities[0, true_label].item()\n",
    "        print(f\"  Segment {i+1}: Predicted Label = {segment_label}, Prediction Score = {segment_score:.4f}, Segment Video Label Score = {segment_video_label_score:.4f}, Segment True Label Score = {segment_true_label_score:.4f}, SV True Label = {sv_true_label[i]:.4f}, SV Predicted Label = {sv_video_pred[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read results, make evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/miniconda3/envs/mmxai/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
      "Processing videos:   0%|          | 0/142 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sv_true_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 选择SV值最高的Top-n个segments进行移除\u001b[39;00m\n\u001b[1;32m     36\u001b[0m top_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 37\u001b[0m segments_to_remove \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msv_true_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[:top_n]\n\u001b[1;32m     38\u001b[0m remove_indices \u001b[38;5;241m=\u001b[39m {seg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegment_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m seg \u001b[38;5;129;01min\u001b[39;00m segments_to_remove}\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 重新加载视频并提取帧\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 37\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 选择SV值最高的Top-n个segments进行移除\u001b[39;00m\n\u001b[1;32m     36\u001b[0m top_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 37\u001b[0m segments_to_remove \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(segments, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msv_true_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:top_n]\n\u001b[1;32m     38\u001b[0m remove_indices \u001b[38;5;241m=\u001b[39m {seg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegment_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m seg \u001b[38;5;129;01min\u001b[39;00m segments_to_remove}\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 重新加载视频并提取帧\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sv_true_label'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import av\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoImageProcessor, TimesformerForVideoClassification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 初始化视频处理器\n",
    "video_processor = VideoProcessor(config[\"model_name\"], config[\"image_processor_name\"])\n",
    "model = video_processor.model\n",
    "\n",
    "# 加载结果文件\n",
    "with open(\"results.json\", \"r\") as file:\n",
    "    results = json.load(file)\n",
    "\n",
    "# 准备用于存储新预测结果的变量\n",
    "true_labels = []\n",
    "original_preds = []\n",
    "modified_preds = []\n",
    "score_differences = []\n",
    "evaluation_results = []\n",
    "\n",
    "# 创建临时目录\n",
    "temp_directory = os.path.join(config[\"video_directory\"], \"temp\")\n",
    "os.makedirs(temp_directory, exist_ok=True)\n",
    "\n",
    "# 使用tqdm创建进度条\n",
    "for result in tqdm(results, desc=\"Processing videos\"):\n",
    "    video_file = result['video_file']\n",
    "    segments = result['segments']\n",
    "    true_label = result['video_true_label']\n",
    "\n",
    "    # 选择SV值最高的Top-n个segments进行移除\n",
    "    top_n = 1\n",
    "    segments_to_remove = sorted(segments, key=lambda x: x['sv_true_label'], reverse=True)[:top_n]\n",
    "    remove_indices = {seg['segment_index'] for seg in segments_to_remove}\n",
    "\n",
    "    # 重新加载视频并提取帧\n",
    "    file_path = os.path.join(config[\"video_directory\"], video_file)\n",
    "    container = av.open(file_path)\n",
    "    frames = [frame.to_image() for frame in container.decode(video=0)]\n",
    "    fps = container.streams.video[0].average_rate\n",
    "    segment_duration = 1\n",
    "    segment_length = int(fps * segment_duration)\n",
    "    total_frames = len(frames)\n",
    "    new_frames = [frames[i] for i in range(total_frames) if (i // segment_length + 1) not in remove_indices]\n",
    "\n",
    "    # 确保仍有帧可用于创建新视频\n",
    "    if not new_frames:\n",
    "        print(f\"All segments removed for {video_file}, skipping video.\")\n",
    "        continue\n",
    "\n",
    "    # 在指定临时目录下保存处理后的视频\n",
    "    output_path = os.path.join(temp_directory, f\"modified_{os.path.basename(video_file)}\")\n",
    "    new_container = av.open(output_path, mode='w')\n",
    "    stream = new_container.add_stream('mpeg4', rate=fps)\n",
    "    for frame in new_frames:\n",
    "        frame = av.VideoFrame.from_image(frame)\n",
    "        packet = stream.encode(frame)\n",
    "        new_container.mux(packet)\n",
    "    new_container.close()\n",
    "\n",
    "    # 使用修改后的视频文件进行预测\n",
    "    new_container = av.open(output_path)\n",
    "    segment_outputs = video_processor.predict_video_and_segments(new_container, true_label)\n",
    "    video_probs = torch.mean(torch.stack([output[2] for output in segment_outputs]), dim=0)\n",
    "    modified_pred_label = video_probs.argmax().item()\n",
    "    modified_pred_score = video_probs[0, modified_pred_label].item()\n",
    "    modified_true_label_score = video_probs[0, true_label].item()\n",
    "\n",
    "    original_true_label_score = result['video_true_score']\n",
    "    score_difference = original_true_label_score - modified_true_label_score\n",
    "    score_differences.append(score_difference)\n",
    "\n",
    "    # 记录新旧预测结果\n",
    "    true_labels.append(true_label)\n",
    "    original_preds.append(result['video_pred_label'])\n",
    "    modified_preds.append(modified_pred_label)\n",
    "\n",
    "    evaluation_results.append({\n",
    "        \"video_file\": video_file,\n",
    "        \"original_prediction\": result['video_pred_label'],\n",
    "        \"original_score\": result['video_pred_score'],\n",
    "        \"original_true_label_score\": original_true_label_score,\n",
    "        \"modified_prediction\": modified_pred_label,\n",
    "        \"modified_score\": modified_pred_score,\n",
    "        \"modified_true_label_score\": modified_true_label_score,\n",
    "        \"true_label\": true_label,\n",
    "        \"score_difference\": score_difference\n",
    "    })\n",
    "\n",
    "# 计算性能指标\n",
    "accuracy = accuracy_score(true_labels, modified_preds)\n",
    "precision = precision_score(true_labels, modified_preds, average='weighted')\n",
    "recall = recall_score(true_labels, modified_preds, average='weighted')\n",
    "f1 = f1_score(true_labels, modified_preds, average='weighted')\n",
    "median_score_difference = np.median(score_differences)\n",
    "\n",
    "# 性能结果保存到evaluation.json\n",
    "evaluation_summary = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": f1,\n",
    "    \"median_score_difference\": median_score_difference,\n",
    "    \"evaluation_details\": evaluation_results\n",
    "}\n",
    "\n",
    "with open(\"evaluation.json\", \"w\") as f:\n",
    "    json.dump(evaluation_summary, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmxai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
