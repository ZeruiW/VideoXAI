{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU Adversarial Pertubation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19796 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/19796 [01:24<23:13:07,  4.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marchive/gaussian_noise_perturbated\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     78\u001b[0m perturbation_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian_noise\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Can be 'gaussian_noise', 'shot_noise', or 'motion_blur'\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[43mprocess_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturbation_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 62\u001b[0m, in \u001b[0;36mprocess_videos\u001b[0;34m(input_folder, output_folder, perturbation_type)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m perturbation_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian_noise\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43madd_gaussian_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m perturbation_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmotion_blur\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     64\u001b[0m     frame \u001b[38;5;241m=\u001b[39m add_motion_blur(frame)\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36madd_gaussian_noise\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_gaussian_noise\u001b[39m(image):\n\u001b[0;32m---> 12\u001b[0m     noisy_image \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgaussian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (noisy_image \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/skimage/util/noise.py:175\u001b[0m, in \u001b[0;36mrandom_noise\u001b[0;34m(image, mode, rng, clip, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39msetdefault(kw, kwdefaults[kw])\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 175\u001b[0m     noise \u001b[38;5;241m=\u001b[39m \u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     out \u001b[38;5;241m=\u001b[39m image \u001b[38;5;241m+\u001b[39m noise\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalvar\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Ensure local variance input is correct\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian\n",
    "from skimage.transform import rescale, AffineTransform, warp\n",
    "from scipy.ndimage import zoom as scizoom\n",
    "\n",
    "def add_gaussian_noise(image):\n",
    "    noisy_image = random_noise(image, mode='gaussian', mean=0, var=0.01)\n",
    "    return (noisy_image * 255).astype(np.uint8)\n",
    "\n",
    "def add_motion_blur(image):\n",
    "    size = 5  # Size of the kernel\n",
    "    kernel_motion_blur = np.zeros((size, size))\n",
    "    kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "    kernel_motion_blur = kernel_motion_blur / size\n",
    "    output = cv2.filter2D(image, -1, kernel_motion_blur)\n",
    "    return output\n",
    "\n",
    "def add_shot_noise(image):\n",
    "    image = image / 255.0\n",
    "    noisy_image = np.random.poisson(image * 255) / 255.0\n",
    "    noisy_image = np.clip(noisy_image, 0, 1) * 255\n",
    "    return noisy_image.astype(np.uint8)\n",
    "\n",
    "def add_zoom_blur(image, zoom_factor=2):\n",
    "    h, w = image.shape[:2]\n",
    "    # Zoom in to the image and then crop to original size\n",
    "    zoomed = scizoom(image, (zoom_factor, zoom_factor, 1))\n",
    "    start_h = (zoomed.shape[0] - h) // 2\n",
    "    start_w = (zoomed.shape[1] - w) // 2\n",
    "    zoomed_cropped = zoomed[start_h:start_h+h, start_w:start_w+w]\n",
    "    return zoomed_cropped.astype(np.uint8)\n",
    "\n",
    "def process_videos(input_folder, output_folder, perturbation_type='gaussian_noise'):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for dirname, _, filenames in os.walk(input_folder):\n",
    "        for filename in tqdm(filenames):\n",
    "            if filename.endswith('.mp4'):\n",
    "                cap = cv2.VideoCapture(os.path.join(dirname, filename))\n",
    "                \n",
    "                # Get properties from input to use on output\n",
    "                frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                \n",
    "                fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "                out_path = os.path.join(output_folder, filename)\n",
    "                out = cv2.VideoWriter(out_path, fourcc, fps, (frame_width, frame_height))\n",
    "                \n",
    "                while True:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    \n",
    "                    if perturbation_type == 'gaussian_noise':\n",
    "                        frame = add_gaussian_noise(frame)\n",
    "                    elif perturbation_type == 'motion_blur':\n",
    "                        frame = add_motion_blur(frame)\n",
    "                    elif perturbation_type == 'shot_noise':\n",
    "                        frame = add_shot_noise(frame)\n",
    "                    elif perturbation_type == 'zoom_blur':\n",
    "                        frame = add_zoom_blur(frame)\n",
    "                    \n",
    "                    out.write(frame)\n",
    "                \n",
    "                cap.release()\n",
    "                out.release()\n",
    "\n",
    "# Example usage:\n",
    "input_folder = 'archive/videos_val'\n",
    "output_folder = 'archive/gaussian_noise_perturbated'\n",
    "perturbation_type = 'gaussian_noise'  # Can be 'gaussian_noise', 'shot_noise', or 'motion_blur'\n",
    "\n",
    "process_videos(input_folder, output_folder, perturbation_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU Adversarial Pertubation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19796 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19796/19796 [8:04:16<00:00,  1.47s/it]  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian\n",
    "from scipy.ndimage import zoom as scizoom\n",
    "\n",
    "# 设置使用的设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 添加高斯噪声\n",
    "def add_gaussian_noise(image, std=0.1):\n",
    "    noise = torch.randn(image.size(), device=device) * std\n",
    "    noisy_image = image + noise\n",
    "    return noisy_image.clamp(0, 1)\n",
    "\n",
    "# 添加射击噪声\n",
    "def add_shot_noise(image, scale=50):\n",
    "    noisy_image = torch.poisson(image * scale) / scale\n",
    "    return noisy_image.clamp(0, 1)\n",
    "\n",
    "# 添加运动模糊\n",
    "def add_motion_blur(image, kernel_size=5):\n",
    "    kernel_motion_blur = torch.zeros((3, 1, kernel_size, kernel_size), device=device)\n",
    "    kernel_motion_blur[:, 0, kernel_size//2, :] = torch.ones(kernel_size)\n",
    "    kernel_motion_blur /= kernel_size\n",
    "    padded_image = torch.nn.functional.pad(image, (kernel_size//2, kernel_size//2, kernel_size//2, kernel_size//2), mode='replicate')\n",
    "    image_blurred = torch.nn.functional.conv2d(padded_image.unsqueeze(0), kernel_motion_blur, groups=3)\n",
    "    return image_blurred.squeeze(0)\n",
    "\n",
    "# 添加缩放模糊\n",
    "def add_zoom_blur(image, zoom_factor=1.1):\n",
    "    h, w = image.shape[1:]\n",
    "    image_zoomed = TF.resize(image, int(zoom_factor * max(h, w)))\n",
    "    center_crop = TF.center_crop(image_zoomed, [h, w])\n",
    "    return center_crop\n",
    "\n",
    "# 视频处理函数\n",
    "def process_videos(input_folder, output_folder, perturbation_type='gaussian_noise', param=0.1):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for filename in tqdm(os.listdir(input_folder)):\n",
    "        if filename.endswith('.mp4'):\n",
    "            cap = cv2.VideoCapture(os.path.join(input_folder, filename))\n",
    "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            \n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out_path = os.path.join(output_folder, filename)\n",
    "            out = cv2.VideoWriter(out_path, fourcc, fps, (frame_width, frame_height))\n",
    "            \n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                frame = TF.to_tensor(frame).to(device)\n",
    "                \n",
    "                if perturbation_type == 'gaussian_noise':\n",
    "                    frame = add_gaussian_noise(frame, std=param)\n",
    "                elif perturbation_type == 'shot_noise':\n",
    "                    frame = add_shot_noise(frame, scale=param)\n",
    "                elif perturbation_type == 'motion_blur':\n",
    "                    frame = add_motion_blur(frame, kernel_size=int(param))\n",
    "                elif perturbation_type == 'zoom_blur':\n",
    "                    frame = add_zoom_blur(frame, zoom_factor=param)\n",
    "                \n",
    "                frame = TF.to_pil_image(frame.cpu())\n",
    "                frame = np.array(frame)\n",
    "                out.write(frame)\n",
    "            \n",
    "            cap.release()\n",
    "            out.release()\n",
    "\n",
    "# Example usage\n",
    "input_folder = 'archive/videos_val'\n",
    "output_folder = 'archive/zoom_blur'\n",
    "perturbation_type = 'zoom_blur'  # Can be 'gaussian_noise', 'shot_noise', 'motion_blur', 'zoom_blur'\n",
    "param = 1.1  # Example parameters: 0.1 for gaussian_noise, 3000 for shot_noise, 5 for motion_blur, 1.1 for zoom_blur\n",
    "\n",
    "process_videos(input_folder, output_folder, perturbation_type, param)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmxai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
